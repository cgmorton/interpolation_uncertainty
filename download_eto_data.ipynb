{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "import ee\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e92463d839a565",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ee.Initialize(\n",
    "    project='ee-cmorton',\n",
    "    opt_url='https://earthengine-highvolume.googleapis.com'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83a0b7c6-3617-43cf-adc3-1849787b6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "et_cell_path = 'et_cell_metadata.csv'\n",
    "# et_cell_path = os.path.join(os.getcwd(), 'et_cell_metadata.csv')\n",
    "\n",
    "eto_ws = os.path.join(os.getcwd(), 'eto')\n",
    "eto_file_prefix = 'eto'\n",
    "\n",
    "years = list(range(1985, 2024))\n",
    "overwrite_flag = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f42994-5741-4f19-b864-97227dbcb96d",
   "metadata": {},
   "source": [
    "## Read in the list of target grid cells/points to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0869986a-a04a-46ca-ab42-88a4e909a5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ET cell count: 11\n"
     ]
    }
   ],
   "source": [
    "et_cell_df = pd.read_csv(et_cell_path)\n",
    "print(f'ET cell count: {len(et_cell_df)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40680e-dd52-4e25-ab46-99ff017a62ca",
   "metadata": {},
   "source": [
    "## Extract and save the ETo time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b3c0a3b-5ead-4061-8bd5-925e131d017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETo files: 429\n",
      "\n",
      "   0 - Cell 387098\n",
      "   1 - Cell 467476\n",
      "   2 - Cell 473008\n",
      "   3 - Cell 511799\n",
      "   4 - Cell 581084\n",
      "   5 - Cell 605776\n",
      "   6 - Cell 661167\n",
      "   7 - Cell 686149\n",
      "   8 - Cell 688961\n",
      "   9 - Cell 564161\n",
      "  10 - Cell 565566\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# We will probably not use all the years, but build all the folder\n",
    "for year in years:\n",
    "    if not os.path.isdir(os.path.join(eto_ws, f'{year}')):\n",
    "        os.makedirs(os.path.join(eto_ws, f'{year}'))\n",
    "\n",
    "eto_files = {\n",
    "    item for year in years\n",
    "    for item in os.listdir(os.path.join(eto_ws, f'{year}')) \n",
    "    if item.endswith('.csv')\n",
    "}\n",
    "print(f'ETo files: {len(eto_files)}\\n')\n",
    "#pprint.pprint(eto_files)\n",
    "\n",
    "\n",
    "for i, et_cell in et_cell_df.iterrows():\n",
    "    cell_id = et_cell[\"GRIDMET_ID\"]\n",
    "    xy = [et_cell['LON'], et_cell['LAT']]\n",
    "    print(f'{i:>4d} - Cell {et_cell[\"GRIDMET_ID\"]}')\n",
    "    \n",
    "    for year in years:\n",
    "        file_name = f'{eto_file_prefix}_{year}_{cell_id}.csv'\n",
    "        file_path = os.path.join(eto_ws, f'{year}', file_name)\n",
    "        if not overwrite_flag and (file_name in eto_files):\n",
    "            continue\n",
    "        # print(f'  {year}')\n",
    "    \n",
    "        # Get the reference ET timeseries\n",
    "        daily_info = (\n",
    "            ee.ImageCollection('projects/openet/assets/reference_et/conus/gridmet/daily/v1')\n",
    "            .filterDate(f'{year}-01-01', f'{year+1}-01-01')\n",
    "            .select(['eto'])\n",
    "            .getRegion(ee.Geometry.Point(xy), 4000)\n",
    "            .getInfo()\n",
    "        )\n",
    "\n",
    "        # Reformat the getInfo output so it can be easily read into a dataframe\n",
    "        daily_dict = {'date': {}, 'eto': {}}\n",
    "        for row in daily_info[1:]:\n",
    "            date = datetime.utcfromtimestamp(row[3] / 1000.0).strftime('%Y-%m-%d')\n",
    "            daily_dict['date'][date] = date\n",
    "            daily_dict['eto'][date] = row[4]\n",
    "            \n",
    "        # Build and save the daily dataframe\n",
    "        daily_df = pd.DataFrame.from_dict(daily_dict)\n",
    "        #daily_df['cell_id'] = et_cell['cell_id']\n",
    "        daily_df['date'] = pd.to_datetime(daily_df['date'], format='%Y-%m-%d')\n",
    "        daily_df.sort_index(inplace=True)\n",
    "        daily_df.to_csv(file_path, index=False)\n",
    "\n",
    "        #del daily_df, daily_dict, daily_info\n",
    "\n",
    "print('\\nDone')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42e8e01-e09e-4197-870e-0d72a15f257d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
